{
  "project": "Sanskrit Analyzer",
  "branchName": "ralph/model-training",
  "description": "Model Training Pipeline - Generate training data from Sanskrit corpora and fine-tune LLMs for grammar analysis and disambiguation",
  "userStories": [
    {
      "id": "US-001",
      "title": "Create training module structure",
      "description": "As a developer, I need the basic module structure for training code so that I have a place to add data generation and training scripts.",
      "acceptanceCriteria": [
        "Create sanskrit_analyzer/training/__init__.py",
        "Create sanskrit_analyzer/training/data_generator.py (empty placeholder)",
        "Create sanskrit_analyzer/training/corpus_loader.py (empty placeholder)",
        "Create sanskrit_analyzer/training/format_converter.py (empty placeholder)",
        "Create sanskrit_analyzer/training/config.py with TrainingConfig dataclass",
        "Typecheck passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Module structure created with config, corpus_loader, data_generator, format_converter"
    },
    {
      "id": "US-002",
      "title": "Implement corpus loader for text files",
      "description": "As a developer, I need to load Sanskrit text corpora from various formats so I can process them for training data.",
      "acceptanceCriteria": [
        "CorpusLoader class in corpus_loader.py",
        "Support loading from plain text files (.txt)",
        "Support loading from JSON files with verse structure",
        "Iterator interface yielding sentences/verses",
        "Track source metadata (corpus name, chapter, verse number)",
        "Typecheck passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": "CorpusLoader with text/JSON support and iterator interface"
    },
    {
      "id": "US-003",
      "title": "Add sample corpus data",
      "description": "As a developer, I need sample Sanskrit text data so I can test the training pipeline.",
      "acceptanceCriteria": [
        "Create sanskrit_analyzer/data/corpora/ directory",
        "Add sample_ramayana.txt with 50-100 verses from Balakanda",
        "Add sample_gita.txt with 20-30 verses",
        "Include proper attribution and source notes",
        "Typecheck passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Sample Ramayana (50 verses) and Gita (25 verses) in data/corpora/"
    },
    {
      "id": "US-004",
      "title": "Implement batch analyzer for corpus processing",
      "description": "As a developer, I need to run the analyzer on corpus texts in batch mode to generate training examples.",
      "acceptanceCriteria": [
        "BatchAnalyzer class in data_generator.py",
        "Process sentences through existing Analyzer",
        "Capture full parse results with confidence scores",
        "Filter results by confidence threshold (configurable, default 0.85)",
        "Save results to JSONL format",
        "Progress tracking with logging",
        "Typecheck passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": "BatchAnalyzer with async processing, JSONL output, and confidence filtering"
    },
    {
      "id": "US-005",
      "title": "Create grammar training data format converter",
      "description": "As a developer, I need to convert analyzer output to the grammar model training format.",
      "acceptanceCriteria": [
        "GrammarFormatConverter class in format_converter.py",
        "Convert ParseResult to training JSON format",
        "Input format: 'Parse: {sanskrit_text}'",
        "Output format: structured JSON with sandhi_groups, words, morphology",
        "Validate output matches expected schema",
        "Typecheck passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": "GrammarFormatConverter with schema validation"
    },
    {
      "id": "US-006",
      "title": "Create disambiguation training data generator",
      "description": "As a developer, I need to generate disambiguation training examples from ambiguous parses.",
      "acceptanceCriteria": [
        "DisambiguationGenerator class in data_generator.py",
        "Identify sentences with multiple parse candidates",
        "Generate reasoning text using rule templates",
        "Output format: parses array, selected index, reasoning string",
        "Templates for: case_agreement, verb_agreement, sandhi_preference, semantic_coherence",
        "Typecheck passes"
      ],
      "priority": 6,
      "passes": true,
      "notes": "DisambiguationGenerator with template-based reasoning"
    },
    {
      "id": "US-007",
      "title": "Add reasoning templates",
      "description": "As a developer, I need reasoning templates so disambiguation examples include explanatory text.",
      "acceptanceCriteria": [
        "Create sanskrit_analyzer/training/reasoning_templates.py",
        "REASONING_TEMPLATES dict with template strings",
        "Templates for: case_agreement, verb_agreement, sandhi_preference, semantic_coherence",
        "Function to fill template with parse-specific details",
        "Typecheck passes"
      ],
      "priority": 7,
      "passes": true,
      "notes": "reasoning_templates.py with 6 templates and fill functions"
    },
    {
      "id": "US-008",
      "title": "Implement training data CLI",
      "description": "As a developer, I need a CLI tool to generate training data from corpora.",
      "acceptanceCriteria": [
        "Create sanskrit_analyzer/training/cli.py",
        "Command: generate-grammar --corpus PATH --output PATH --min-confidence 0.85",
        "Command: generate-disambig --corpus PATH --output PATH",
        "Progress bar for long operations",
        "Summary statistics at completion",
        "Typecheck passes"
      ],
      "priority": 8,
      "passes": true,
      "notes": "CLI with generate-grammar, generate-disambig, validate, stats commands"
    },
    {
      "id": "US-009",
      "title": "Add training CLI entry point",
      "description": "As a developer, I need a proper entry point so the training CLI can be easily invoked.",
      "acceptanceCriteria": [
        "Add [project.scripts] entry: sanskrit-train = sanskrit_analyzer.training.cli:main",
        "CLI can be started with sanskrit-train command after install",
        "Help text documents available commands",
        "Typecheck passes"
      ],
      "priority": 9,
      "passes": true,
      "notes": "Entry point sanskrit-train added to pyproject.toml"
    },
    {
      "id": "US-010",
      "title": "Create data validation utilities",
      "description": "As a developer, I need validation utilities to ensure training data quality.",
      "acceptanceCriteria": [
        "Create sanskrit_analyzer/training/validation.py",
        "validate_grammar_example() checks JSON schema compliance",
        "validate_disambig_example() checks required fields",
        "Report invalid examples with specific errors",
        "CLI command: sanskrit-train validate --input PATH",
        "Typecheck passes"
      ],
      "priority": 10,
      "passes": true,
      "notes": "Validation in format_converter.py and CLI validate command"
    },
    {
      "id": "US-011",
      "title": "Add unit tests for corpus loader",
      "description": "As a developer, I need unit tests for the corpus loader.",
      "acceptanceCriteria": [
        "Create tests/training/test_corpus_loader.py",
        "Test loading text files",
        "Test loading JSON files",
        "Test metadata tracking",
        "Test iterator behavior",
        "All tests pass"
      ],
      "priority": 11,
      "passes": true,
      "notes": "13 tests in test_corpus_loader.py"
    },
    {
      "id": "US-012",
      "title": "Add unit tests for format converters",
      "description": "As a developer, I need unit tests for the format converters.",
      "acceptanceCriteria": [
        "Create tests/training/test_format_converter.py",
        "Test grammar format conversion",
        "Test disambiguation format conversion",
        "Test reasoning template filling",
        "Test schema validation",
        "All tests pass"
      ],
      "priority": 12,
      "passes": true,
      "notes": "17 tests in test_format_converter.py"
    },
    {
      "id": "US-013",
      "title": "Add integration test for full pipeline",
      "description": "As a developer, I need integration tests for the full training data generation pipeline.",
      "acceptanceCriteria": [
        "Create tests/training/test_integration.py",
        "Test end-to-end: corpus → analyze → format → validate",
        "Test with sample corpus data",
        "Verify output file formats",
        "All tests pass"
      ],
      "priority": 13,
      "passes": true,
      "notes": "8 tests in test_integration.py"
    },
    {
      "id": "US-014",
      "title": "Create training data statistics utility",
      "description": "As a developer, I need to generate statistics about training datasets.",
      "acceptanceCriteria": [
        "Add stats command to CLI: sanskrit-train stats --input PATH",
        "Report: total examples, avg confidence, morphology distribution",
        "Report: disambiguation reasoning type distribution",
        "Output as JSON or formatted text",
        "Typecheck passes"
      ],
      "priority": 14,
      "passes": true,
      "notes": "Stats command in CLI with JSON output option"
    },
    {
      "id": "US-015",
      "title": "Document training data generation",
      "description": "As a developer, I need documentation on how to generate training data.",
      "acceptanceCriteria": [
        "Create sanskrit_analyzer/training/README.md",
        "Document corpus format requirements",
        "Document CLI commands with examples",
        "Document output formats with samples",
        "Update main README.md with training section"
      ],
      "priority": 15,
      "passes": true,
      "notes": "README.md created in training module"
    }
  ]
}
